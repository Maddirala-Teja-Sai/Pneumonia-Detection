{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10338,"databundleVersionId":862042,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#RSNA DATASET\n\n# Install required packages (if not preinstalled)\n!pip install -q pydicom opencv-python-headless\n\nimport os\nimport cv2\nimport torch\nimport numpy as np\nimport pydicom\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.models import vit_b_16\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# ✅ Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ✅ Paths\nbase_path = '/kaggle/input/rsna-pneumonia-detection-challenge'\ntrain_img_path = os.path.join(base_path, 'stage_2_train_images')\ntest_img_path = os.path.join(base_path, 'stage_2_test_images')\nlabels_csv_path = os.path.join(base_path, 'stage_2_train_labels.csv')\nsample_submission_path = os.path.join(base_path, 'stage_2_sample_submission.csv')\n\n# ✅ Load train labels\ndef load_labels(path):\n    df = pd.read_csv(path)\n    labels = {}\n    for _, row in df.iterrows():\n        labels[row['patientId']] = 1 if row['Target'] == 1 else 0\n    return labels\n\nlabels_dict = load_labels(labels_csv_path)\n\n# ✅ Image preprocessing (CLAHE + denoise + hist eq)\ndef preprocess_image(image):\n    image = cv2.convertScaleAbs(image, alpha=1.5, beta=0)\n    image = cv2.equalizeHist(image)\n    clahe = cv2.createCLAHE(clipLimit=2.0)\n    image = clahe.apply(image)\n    image = cv2.fastNlMeansDenoising(image, h=10)\n    return image\n\n# ✅ Dataset for train/test\nclass RSNADataset(Dataset):\n    def __init__(self, img_dir, labels_dict=None, transform=None, limit=None):\n        self.img_dir = img_dir\n        self.image_names = sorted([f for f in os.listdir(img_dir) if f.endswith(\".dcm\")])\n        if limit:\n            self.image_names = self.image_names[:limit]\n        self.labels_dict = labels_dict\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        fname = self.image_names[idx]\n        fpath = os.path.join(self.img_dir, fname)\n        dcm = pydicom.dcmread(fpath)\n        image = dcm.pixel_array.astype(np.uint8)\n        image = preprocess_image(image)\n        image = cv2.resize(image, (224, 224))\n        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.labels_dict:\n            patient_id = fname.replace(\".dcm\", \"\")\n            label = self.labels_dict.get(patient_id, 0)\n            return image, label\n        else:\n            return image, fname.replace(\".dcm\", \"\")  # for test set\n\n# ✅ Transforms\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3),\n])\n\n# ✅ Datasets and Loaders\ntrain_dataset = RSNADataset(train_img_path, labels_dict, transform=transform, limit=3000)\ntest_dataset = RSNADataset(test_img_path, labels_dict=None, transform=transform, limit=1000)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n\n# ✅ Model\nmodel = vit_b_16(pretrained=True)\nmodel.heads.head = torch.nn.Linear(model.heads.head.in_features, 2)\nmodel = model.to(device)\n\n# ✅ Loss & Optimizer\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\n# ✅ Training\nepochs = 3\nfor epoch in range(epochs):\n    model.train()\n    running_loss, correct, total = 0, 0, 0\n    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n\n    for images, labels in loop:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        _, preds = torch.max(outputs, 1)\n        running_loss += loss.item()\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n        loop.set_postfix(loss=running_loss/total, acc=100.*correct/total)\n\n# ✅ Evaluate on train data\nmodel.eval()\ny_true, y_pred = [], []\n\nwith torch.no_grad():\n    for images, labels in tqdm(train_loader, desc=\"Evaluating\"):\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\nprint(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n\n# ✅ Predict on test set and create submission\nmodel.eval()\npredictions = []\nids = []\n\nwith torch.no_grad():\n    for images, patient_ids in tqdm(test_loader, desc=\"Predicting on Test Set\"):\n        images = images.to(device)\n        outputs = model(images)\n        probs = torch.nn.functional.softmax(outputs, dim=1)\n        preds = probs[:, 1].cpu().numpy()\n        predictions.extend(preds)\n        ids.extend(patient_ids)\n\nsubmission_df = pd.DataFrame({'patientId': ids, 'Target': predictions})\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"✅ submission.csv created.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}